{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv6whY1wdUyN"
      },
      "source": [
        "### READ ME\n",
        "\n",
        "Use the code blocks below to answer each question. Only print the output required for each question. Do not edit the comments at the top of each code cell. Otherwise, the auto-grader may misinterpret your results. See Question 0 as an an example of how to complete a task (leave it in your notebook; don't delete it):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LldV48pCdeRB",
        "outputId": "aa44b626-b668-4fe3-d870-f811e40bb480"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "n1V1eFxCdUyQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tweet_id                      0\n",
            "text                          0\n",
            "context_annotations_count     0\n",
            "count_annotations             0\n",
            "count_cashtags                0\n",
            "count_hashtags                0\n",
            "count_mentions                0\n",
            "count_urls                    0\n",
            "created_at_tweet              0\n",
            "lang                          0\n",
            "likes                         0\n",
            "quotes                        0\n",
            "referenced_tweet_count        0\n",
            "replies                       0\n",
            "reply_settings                0\n",
            "retweets                      0\n",
            "source                        0\n",
            "terms                         0\n",
            "username                      0\n",
            "created_at_author             0\n",
            "followers_count               0\n",
            "following_count               0\n",
            "tweet_count                   0\n",
            "listed_count                  0\n",
            "location                     42\n",
            "protected                     0\n",
            "verified                      0\n",
            "media_type                    0\n",
            "height                        0\n",
            "width                         0\n",
            "preview_image_url             0\n",
            "country                       0\n",
            "name_place                    0\n",
            "place_type                    0\n",
            "dtype: int64\n",
            "-------------------------------------------------\n",
            "skewness: 12.193283459209416\n",
            "-------------------------------------------------\n",
            "skewness after log: 1.282185198437661\n",
            "-------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>context_annotations_count</th>\n",
              "      <th>count_annotations</th>\n",
              "      <th>count_cashtags</th>\n",
              "      <th>count_hashtags</th>\n",
              "      <th>count_mentions</th>\n",
              "      <th>count_urls</th>\n",
              "      <th>created_at_tweet</th>\n",
              "      <th>lang</th>\n",
              "      <th>...</th>\n",
              "      <th>location</th>\n",
              "      <th>protected</th>\n",
              "      <th>verified</th>\n",
              "      <th>media_type</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>preview_image_url</th>\n",
              "      <th>country</th>\n",
              "      <th>name_place</th>\n",
              "      <th>place_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1440484799970304000</td>\n",
              "      <td>This was my grandson this morning (w/autism)! ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-09-22T01:15:13.000Z</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Victoria,  BC</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>photo</td>\n",
              "      <td>405</td>\n",
              "      <td>813</td>\n",
              "      <td>https://pbs.twimg.com/media/E_2hSs4UcAAIOK5.jpg</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Langford</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1439618825171963904</td>\n",
              "      <td>Wow!! Been into #York for the first time since...</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-09-19T15:54:09.000Z</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Hessay, York</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>photo</td>\n",
              "      <td>2048</td>\n",
              "      <td>1536</td>\n",
              "      <td>https://pbs.twimg.com/media/E_qNsE1X0AQmoK_.jpg</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Hessay</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1248872872837332992</td>\n",
              "      <td>Sad number of ppl who lost life due to covid-1...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2020-04-11T07:17:50.000Z</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Maidstone, South East</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>photo</td>\n",
              "      <td>288</td>\n",
              "      <td>278</td>\n",
              "      <td>https://pbs.twimg.com/media/EVTjQcoXsAAlrfq.jpg</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Maidstone</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1250729294051053568</td>\n",
              "      <td>Webinar now available‘Staying healthy at home ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2020-04-16T10:14:35.000Z</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Maidstone, South East</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>photo</td>\n",
              "      <td>2048</td>\n",
              "      <td>2048</td>\n",
              "      <td>https://pbs.twimg.com/media/EVt7pYTXkAMGzxj.jpg</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Maidstone</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1249612131433095168</td>\n",
              "      <td>Webinar now available‘Staying healthy at home ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2020-04-13T08:15:23.000Z</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Maidstone, South East</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>photo</td>\n",
              "      <td>2048</td>\n",
              "      <td>2048</td>\n",
              "      <td>https://pbs.twimg.com/media/EVeDlp7X0AMuN6X.jpg</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Maidstone</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id                                               text  \\\n",
              "0  1440484799970304000  This was my grandson this morning (w/autism)! ...   \n",
              "1  1439618825171963904  Wow!! Been into #York for the first time since...   \n",
              "2  1248872872837332992  Sad number of ppl who lost life due to covid-1...   \n",
              "3  1250729294051053568  Webinar now available‘Staying healthy at home ...   \n",
              "4  1249612131433095168  Webinar now available‘Staying healthy at home ...   \n",
              "\n",
              "   context_annotations_count  count_annotations  count_cashtags  \\\n",
              "0                          1                0.0             0.0   \n",
              "1                          2                2.0             0.0   \n",
              "2                          3                0.0             0.0   \n",
              "3                          1                2.0             0.0   \n",
              "4                          1                2.0             0.0   \n",
              "\n",
              "   count_hashtags  count_mentions  count_urls          created_at_tweet lang  \\\n",
              "0             0.0             0.0         1.0  2021-09-22T01:15:13.000Z   en   \n",
              "1             3.0             0.0         1.0  2021-09-19T15:54:09.000Z   en   \n",
              "2             0.0             0.0         1.0  2020-04-11T07:17:50.000Z   en   \n",
              "3             3.0             0.0         2.0  2020-04-16T10:14:35.000Z   en   \n",
              "4             3.0             0.0         2.0  2020-04-13T08:15:23.000Z   en   \n",
              "\n",
              "   ...               location  protected  verified  media_type height  width  \\\n",
              "0  ...         Victoria,  BC       False     False       photo    405    813   \n",
              "1  ...           Hessay, York      False     False       photo   2048   1536   \n",
              "2  ...  Maidstone, South East      False     False       photo    288    278   \n",
              "3  ...  Maidstone, South East      False     False       photo   2048   2048   \n",
              "4  ...  Maidstone, South East      False     False       photo   2048   2048   \n",
              "\n",
              "                                 preview_image_url         country name_place  \\\n",
              "0  https://pbs.twimg.com/media/E_2hSs4UcAAIOK5.jpg          Canada   Langford   \n",
              "1  https://pbs.twimg.com/media/E_qNsE1X0AQmoK_.jpg  United Kingdom     Hessay   \n",
              "2  https://pbs.twimg.com/media/EVTjQcoXsAAlrfq.jpg  United Kingdom  Maidstone   \n",
              "3  https://pbs.twimg.com/media/EVt7pYTXkAMGzxj.jpg  United Kingdom  Maidstone   \n",
              "4  https://pbs.twimg.com/media/EVeDlp7X0AMuN6X.jpg  United Kingdom  Maidstone   \n",
              "\n",
              "  place_type  \n",
              "0       city  \n",
              "1       city  \n",
              "2       city  \n",
              "3       city  \n",
              "4       city  \n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Question 1: Import the data here and perform any data cleaning\n",
        "# steps that you feel are necessary in this code cell. Keep all \n",
        "# cleaning steps here in the same code cell. First, check for missing\n",
        "# values and print out the totals. If you have missing values, then\n",
        "# either replace them (.fillna()) with a theoretically meaningful \n",
        "# value (e.g. 'other' or 0) or delete the column. You may delete rows\n",
        "# as long as you can maintain a final row count >= 500.\n",
        "# \n",
        "# Next, check for label skewness and print out the skewness scores. \n",
        "# Make an adjustment to the label if the skewness is > 1 or < -1. If \n",
        "# you cannot get the label between -1 to 1 after making an adjustment, \n",
        "# that is okay for now. It just means that, in practice, you would switch\n",
        "# to using a Decision Trees regression model rather than MLR. \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#import data set\n",
        "df = pd.read_csv('tw_tweets_users_media_places.csv')\n",
        "\n",
        "#check for missing values\n",
        "print(df.isnull().sum())\n",
        "print('-------------------------------------------------')\n",
        "\n",
        "# fill in missing values in the location column\n",
        "df['location'].fillna('Other', inplace=True)\n",
        "\n",
        "#check for label skewness\n",
        "label = 'likes'\n",
        "print('skewness: ' + str(df[label].skew()))\n",
        "print('-------------------------------------------------')\n",
        "\n",
        "# use natural log to transform the label\n",
        "df[label] = np.log1p(df[label])\n",
        "print('skewness after log: ' + str(df[label].skew()))\n",
        "print('-------------------------------------------------')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUjC8kPn8du5"
      },
      "source": [
        "## **MLR Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "wAXURAM8dUyR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting R Squared 0.12407988932804592\n",
            "Dropping Charleston, SC with a p-value of 0.9903293822261565.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping Charleston with a p-value of 0.9903293822455881.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping Walsall, England with a p-value of 0.8480140284952761.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping Willenhall with a p-value of 0.8480140284665176.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping Little Rock with a p-value of 0.7933474343543604.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping covid%20\"sensory overload\" with a p-value of 0.7933474343457015.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping Greenock, Scotland with a p-value of 0.5433148071078584.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping Greenock with a p-value of 0.5433148070993097.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping corona%20autism with a p-value of 0.41458932708690144.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping tweet_count with a p-value of 0.3985844318689902.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping Nottingham, England with a p-value of 0.40847484599590766.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "Dropping Garston with a p-value of 0.40847484687729896.\n",
            "New r sqr/adjusted difference 0.0.\n",
            "FINAL\n",
            "final R squared 0.12294934900754606\n"
          ]
        }
      ],
      "source": [
        "# Question 2: Build an MLR model based on one of the labels you \n",
        "# identified and collected during the Web Scraping Project. Keep \n",
        "# all of the code contained here in this code block. You should \n",
        "# have at least one or more features that need to be dummy coded. \n",
        "# Scale the data using a MinMax normalization. Do not include any\n",
        "# unstructured features such as tweet text, product description, \n",
        "# or image URLs.\n",
        "# \n",
        "# After you have build the first MLR model, trim all of the \n",
        "# insignificant features from the model so that only those \n",
        "# with p-values < 0.20 are included in your model. Yes, that is \n",
        "# higher than the typical 0.05 cutoff. However, if you have only\n",
        "# 500 records, it is not uncommon to accept higher p-values. You\n",
        "# do not need to split the data for this model if you are using the\n",
        "# statsmodels.api package as we do in the book. Although you\n",
        "# normally would in practice.\n",
        "import statsmodels.api as sm\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#drop tweet text, image urls\n",
        "df.drop(columns=['text', 'created_at_tweet', 'preview_image_url', 'username', 'created_at_author'], inplace=True)\n",
        "\n",
        "#drop alternative labels\n",
        "df.drop(columns=['retweets', 'replies'], inplace=True)\n",
        "\n",
        "#make dummy codes\n",
        "df_dummies = df.copy()\n",
        "\n",
        "for col in df:\n",
        "  if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "    df_dummies = pd.get_dummies(df_dummies, columns=[col], drop_first=True, prefix=\"\", prefix_sep=\"\")\n",
        "\n",
        "#standardize the data\n",
        "df_minmax = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(df_dummies), columns=df_dummies.columns)\n",
        "\n",
        "#run the MLR\n",
        "def mlr():\n",
        "  y = df_dummies[label]\n",
        "  X = df_dummies.drop(columns=label).assign(const=1)\n",
        "  results = sm.OLS(y, X.astype(float)).fit()\n",
        "  return results\n",
        "results = mlr()\n",
        "# print(results.summary())\n",
        "\n",
        "print(f'starting R Squared {results.rsquared}')\n",
        "while (abs(results.pvalues.sort_values(ascending=False)[0]) > 0.20): #THIS NEEDS TO BE CHANGED TO P VALUE\n",
        "    # get the highest p-value column\n",
        "    highestCol = (results.pvalues.sort_values(ascending=False)).index[0]\n",
        "    print(f'Dropping {highestCol} with a p-value of {(results.pvalues.sort_values(ascending=False))[0]}.')\n",
        "    df_dummies.drop(columns=[highestCol], inplace=True)\n",
        "    # re-run the model\n",
        "    y = df_dummies[label]\n",
        "    X = df_dummies.drop(columns=[label]).assign(const=1)\n",
        "    model = sm.OLS(y, X.astype(float))\n",
        "    results = model.fit()\n",
        "    print(f'New r sqr/adjusted difference {abs(results.rsquared_adj-results.rsquared)}.')\n",
        "print(\"FINAL\")\n",
        "print(f'final R squared {results.rsquared}')\n",
        "# df.head(5)\n",
        "# print(results.pvalues().sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRd8Jixj8ToW"
      },
      "source": [
        "## **Decision Tree Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "FgwbzbRmdUyS"
      },
      "outputs": [],
      "source": [
        "# Question 3: Build a Decision Tree model based on one of the categorical\n",
        "# labels you identified and collected during the Web Scraping Project. Keep \n",
        "# all of the code contained here in this code block. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "U29746C-1WQ-"
      },
      "outputs": [],
      "source": [
        "# Question 4: Create a visualization of the Decision Tree model so that\n",
        "# you can interpret the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsaL9eMn1WQ_"
      },
      "source": [
        "## **Cluster Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "8i8wt4aJ1WRA"
      },
      "outputs": [],
      "source": [
        "# Question 5: Build a cluster model using either K-means or Agglomerative\n",
        "# clustering based on which you think is best for your data type. Remember,\n",
        "# k-means is best when the data types and scales are uniform and\n",
        "# agglomerative is best when both are mixed. If you used k-means, then\n",
        "# calculate all three metrics for determining the optimal number of clusters.\n",
        "# If you use agglomerative clustering, use the Gower matrix as the distance\n",
        "# measure. With either clustering algorithm, print out a value_counts() of the \n",
        "# number of cases in each cluster. Keep all code in this code cell. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Checkpoint_Modeling_project.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "67645e4edde45144644326d4815cd26b14c8093db79836f9b69d4c3e18d9122c"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit (windows store)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
