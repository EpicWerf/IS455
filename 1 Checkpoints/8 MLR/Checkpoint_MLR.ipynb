{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"Checkpoint_MLR.ipynb","provenance":[{"file_id":"1AiDTOu047M87qJMSwJgSyg07ol0GkBqK","timestamp":1633638576803}],"collapsed_sections":[],"mount_file_id":"1AiDTOu047M87qJMSwJgSyg07ol0GkBqK","authorship_tag":"ABX9TyMua3jpK3XG3tDvIPUDAydX"},"kernelspec":{"name":"python3","display_name":"Python 3.8.10 64-bit (windows store)"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"67645e4edde45144644326d4815cd26b14c8093db79836f9b69d4c3e18d9122c"}},"cells":[{"cell_type":"markdown","source":["### READ ME\n","\n","Use the code blocks below to answer each question. Only print the output required for each question. Do not edit the comments at the top of each code cell. Otherwise, the auto-grader may misinterpret your results. See Question 0 as an an example of how to complete a task (leave it in your notebook; don't delete it):"],"metadata":{"id":"E6QnnVUzmJnQ"}},{"cell_type":"code","execution_count":24,"source":["# Question 0: Create a DataFrame with three rows and four columns. Name the \r\n","# columns 'Col1', 'Col2', 'Col3', 'Col4'. Create an index for the DataFrame\r\n","# and give the rows the index values of 'Row1', 'Row2', 'Row3'. Place a value\r\n","# in each column equal to the {ColumnName/RowName}. e.g. Col1/Row1. Print\r\n","# the entire DataFrame.\r\n","\r\n","import pandas as pd\r\n","\r\n","df = pd.DataFrame(columns=['Col1', 'Col2', 'Col3', 'Col4'], index=['Row1', 'Row2', 'Row3'])\r\n","\r\n","for col in df:\r\n","  for i, value in df[col].items():\r\n","    df.at[i, col] = f'{i}/{col}'\r\n","\r\n","df"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Col1</th>\n","      <th>Col2</th>\n","      <th>Col3</th>\n","      <th>Col4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Row1</th>\n","      <td>Row1/Col1</td>\n","      <td>Row1/Col2</td>\n","      <td>Row1/Col3</td>\n","      <td>Row1/Col4</td>\n","    </tr>\n","    <tr>\n","      <th>Row2</th>\n","      <td>Row2/Col1</td>\n","      <td>Row2/Col2</td>\n","      <td>Row2/Col3</td>\n","      <td>Row2/Col4</td>\n","    </tr>\n","    <tr>\n","      <th>Row3</th>\n","      <td>Row3/Col1</td>\n","      <td>Row3/Col2</td>\n","      <td>Row3/Col3</td>\n","      <td>Row3/Col4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Col1       Col2       Col3       Col4\n","Row1  Row1/Col1  Row1/Col2  Row1/Col3  Row1/Col4\n","Row2  Row2/Col1  Row2/Col2  Row2/Col3  Row2/Col4\n","Row3  Row3/Col1  Row3/Col2  Row3/Col3  Row3/Col4"]},"metadata":{},"execution_count":24}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"Fvzzw3w-mAUN","executionInfo":{"status":"ok","timestamp":1633638739222,"user_tz":360,"elapsed":128,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}},"outputId":"d7e9e933-4823-402f-8e88-8a81940213d1"}},{"cell_type":"code","execution_count":25,"source":["# Question 1: Import the datafile tw_tweets_users_media_places.csv that was \r\n","# provided with this checkpoint. Set tweet_id as the index. Print the number \r\n","# of records in this dataset in the output. How many records are there?\r\n","\r\n","import pandas as pd, statsmodels.api as sm\r\n","\r\n","df = pd.read_csv('tw_tweets_users_media_places.csv', index_col='tweet_id')\r\n","print(len(df))"],"outputs":[{"output_type":"stream","name":"stdout","text":["534\n"]}],"metadata":{"id":"GlaDXTIXmMRc","executionInfo":{"status":"ok","timestamp":1633638739222,"user_tz":360,"elapsed":4,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":30,"source":["# Question 2: Make a copy of the DataFrame with all non-numeric features\r\n","# removed. Print out a list of the remaining columns in the output. Print\r\n","# the first five records of this reduced dataset.\r\n","\r\n","df_copy = df.select_dtypes(['number'])\r\n","print(df_copy.columns)\r\n","df_copy.head()"],"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['context_annotations_count', 'count_annotations', 'count_cashtags',\n","       'count_hashtags', 'count_mentions', 'count_urls', 'likes', 'quotes',\n","       'referenced_tweet_count', 'replies', 'retweets', 'followers_count',\n","       'following_count', 'tweet_count', 'listed_count', 'height', 'width'],\n","      dtype='object')\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>context_annotations_count</th>\n","      <th>count_annotations</th>\n","      <th>count_cashtags</th>\n","      <th>count_hashtags</th>\n","      <th>count_mentions</th>\n","      <th>count_urls</th>\n","      <th>likes</th>\n","      <th>quotes</th>\n","      <th>referenced_tweet_count</th>\n","      <th>replies</th>\n","      <th>retweets</th>\n","      <th>followers_count</th>\n","      <th>following_count</th>\n","      <th>tweet_count</th>\n","      <th>listed_count</th>\n","      <th>height</th>\n","      <th>width</th>\n","    </tr>\n","    <tr>\n","      <th>tweet_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1440484799970304000</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>2709</td>\n","      <td>4999</td>\n","      <td>96</td>\n","      <td>15</td>\n","      <td>405</td>\n","      <td>813</td>\n","    </tr>\n","    <tr>\n","      <th>1439618825171963904</th>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>140</td>\n","      <td>735</td>\n","      <td>99</td>\n","      <td>0</td>\n","      <td>2048</td>\n","      <td>1536</td>\n","    </tr>\n","    <tr>\n","      <th>1248872872837332992</th>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>49</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>7510</td>\n","      <td>7260</td>\n","      <td>100</td>\n","      <td>103</td>\n","      <td>288</td>\n","      <td>278</td>\n","    </tr>\n","    <tr>\n","      <th>1250729294051053568</th>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>7510</td>\n","      <td>7260</td>\n","      <td>100</td>\n","      <td>103</td>\n","      <td>2048</td>\n","      <td>2048</td>\n","    </tr>\n","    <tr>\n","      <th>1249612131433095168</th>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>15</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>7510</td>\n","      <td>7260</td>\n","      <td>100</td>\n","      <td>103</td>\n","      <td>2048</td>\n","      <td>2048</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     context_annotations_count  count_annotations  \\\n","tweet_id                                                            \n","1440484799970304000                          1                0.0   \n","1439618825171963904                          2                2.0   \n","1248872872837332992                          3                0.0   \n","1250729294051053568                          1                2.0   \n","1249612131433095168                          1                2.0   \n","\n","                     count_cashtags  count_hashtags  count_mentions  \\\n","tweet_id                                                              \n","1440484799970304000             0.0             0.0             0.0   \n","1439618825171963904             0.0             3.0             0.0   \n","1248872872837332992             0.0             0.0             0.0   \n","1250729294051053568             0.0             3.0             0.0   \n","1249612131433095168             0.0             3.0             0.0   \n","\n","                     count_urls  likes  quotes  referenced_tweet_count  \\\n","tweet_id                                                                 \n","1440484799970304000         1.0     14       0                       0   \n","1439618825171963904         1.0      7       0                       0   \n","1248872872837332992         1.0     49       1                       0   \n","1250729294051053568         2.0      3       0                       0   \n","1249612131433095168         2.0     15       2                       0   \n","\n","                     replies  retweets  followers_count  following_count  \\\n","tweet_id                                                                   \n","1440484799970304000        8         0             2709             4999   \n","1439618825171963904        0         0              140              735   \n","1248872872837332992        0        20             7510             7260   \n","1250729294051053568        0         1             7510             7260   \n","1249612131433095168        0        21             7510             7260   \n","\n","                     tweet_count  listed_count  height  width  \n","tweet_id                                                       \n","1440484799970304000           96            15     405    813  \n","1439618825171963904           99             0    2048   1536  \n","1248872872837332992          100           103     288    278  \n","1250729294051053568          100           103    2048   2048  \n","1249612131433095168          100           103    2048   2048  "]},"metadata":{},"execution_count":30}],"metadata":{"id":"6cshHRGgnj-r","executionInfo":{"status":"ok","timestamp":1633638739222,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":33,"source":["# Question 3: Using 'retweets' as the label, create an MLR model using all\r\n","# features except 'likes', 'quotes', 'replies', and the label. These features\r\n","# each represent outcomes, or alternatives to the label 'rewteets.' If our\r\n","# plan is to use this model to predict the popularity of new potential tweets,\r\n","# then we would not know what the likes, quotes, or replies will be. Therefore,\r\n","# we will eliminate them from the model. Print out the model results summary.\r\n","\r\n","y = df_copy['retweets']\r\n","X = df_copy.drop(['retweets', 'likes', 'quotes', 'replies'], axis=1)\r\n","results = sm.OLS(y, X.astype(float)).fit()\r\n","print(results.summary())"],"outputs":[{"output_type":"stream","name":"stdout","text":["                                 OLS Regression Results                                \n","=======================================================================================\n","Dep. Variable:               retweets   R-squared (uncentered):                   0.103\n","Model:                            OLS   Adj. R-squared (uncentered):              0.083\n","Method:                 Least Squares   F-statistic:                              5.010\n","Date:                Mon, 11 Oct 2021   Prob (F-statistic):                    6.57e-08\n","Time:                        13:38:51   Log-Likelihood:                         -2330.5\n","No. Observations:                 534   AIC:                                      4685.\n","Df Residuals:                     522   BIC:                                      4736.\n","Df Model:                          12                                                  \n","Covariance Type:            nonrobust                                                  \n","=============================================================================================\n","                                coef    std err          t      P>|t|      [0.025      0.975]\n","---------------------------------------------------------------------------------------------\n","context_annotations_count     0.1142      0.265      0.431      0.667      -0.406       0.635\n","count_annotations            -0.7043      0.896     -0.786      0.432      -2.464       1.056\n","count_cashtags               -1.0477      9.673     -0.108      0.914     -20.051      17.955\n","count_hashtags               -0.1655      0.183     -0.904      0.367      -0.525       0.194\n","count_mentions            -6.413e-13   3.83e-12     -0.168      0.867   -8.16e-12    6.88e-12\n","count_urls                    0.5960      1.437      0.415      0.678      -2.227       3.419\n","referenced_tweet_count       -2.2202      2.861     -0.776      0.438      -7.841       3.400\n","followers_count            6.285e-05   6.11e-05      1.029      0.304   -5.72e-05       0.000\n","following_count              -0.0001      0.000     -0.859      0.391      -0.000       0.000\n","tweet_count               -5.901e-05   6.94e-05     -0.850      0.396      -0.000    7.74e-05\n","listed_count                  0.0038      0.009      0.407      0.684      -0.015       0.022\n","height                       -0.0019      0.002     -1.010      0.313      -0.006       0.002\n","width                         0.0049      0.002      2.189      0.029       0.001       0.009\n","==============================================================================\n","Omnibus:                     1028.970   Durbin-Watson:                   2.035\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):           935916.234\n","Skew:                          13.197   Prob(JB):                         0.00\n","Kurtosis:                     206.389   Cond. No.                     3.98e+19\n","==============================================================================\n","\n","Notes:\n","[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n","[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[3] The smallest eigenvalue is 1.17e-27. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n"]}],"metadata":{"id":"FlptvGIhoMkd","executionInfo":{"status":"ok","timestamp":1633638739329,"user_tz":360,"elapsed":110,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":36,"source":["# Question 4: Add the scored (i.e. predicted) values for every record \r\n","# back into the original dataframe using the column label \"model_1\". Print\r\n","# the first five records.\r\n","df = df_copy.assign(model_1=results.predict(X))\r\n","df.head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>context_annotations_count</th>\n","      <th>count_annotations</th>\n","      <th>count_cashtags</th>\n","      <th>count_hashtags</th>\n","      <th>count_mentions</th>\n","      <th>count_urls</th>\n","      <th>likes</th>\n","      <th>quotes</th>\n","      <th>referenced_tweet_count</th>\n","      <th>replies</th>\n","      <th>retweets</th>\n","      <th>followers_count</th>\n","      <th>following_count</th>\n","      <th>tweet_count</th>\n","      <th>listed_count</th>\n","      <th>height</th>\n","      <th>width</th>\n","      <th>model_1</th>\n","    </tr>\n","    <tr>\n","      <th>tweet_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1440484799970304000</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>2709</td>\n","      <td>4999</td>\n","      <td>96</td>\n","      <td>15</td>\n","      <td>405</td>\n","      <td>813</td>\n","      <td>3.586778</td>\n","    </tr>\n","    <tr>\n","      <th>1439618825171963904</th>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>140</td>\n","      <td>735</td>\n","      <td>99</td>\n","      <td>0</td>\n","      <td>2048</td>\n","      <td>1536</td>\n","      <td>2.439114</td>\n","    </tr>\n","    <tr>\n","      <th>1248872872837332992</th>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>49</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>7510</td>\n","      <td>7260</td>\n","      <td>100</td>\n","      <td>103</td>\n","      <td>288</td>\n","      <td>278</td>\n","      <td>1.789965</td>\n","    </tr>\n","    <tr>\n","      <th>1250729294051053568</th>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>7510</td>\n","      <td>7260</td>\n","      <td>100</td>\n","      <td>103</td>\n","      <td>2048</td>\n","      <td>2048</td>\n","      <td>5.563298</td>\n","    </tr>\n","    <tr>\n","      <th>1249612131433095168</th>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>15</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>7510</td>\n","      <td>7260</td>\n","      <td>100</td>\n","      <td>103</td>\n","      <td>2048</td>\n","      <td>2048</td>\n","      <td>5.563298</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     context_annotations_count  count_annotations  \\\n","tweet_id                                                            \n","1440484799970304000                          1                0.0   \n","1439618825171963904                          2                2.0   \n","1248872872837332992                          3                0.0   \n","1250729294051053568                          1                2.0   \n","1249612131433095168                          1                2.0   \n","\n","                     count_cashtags  count_hashtags  count_mentions  \\\n","tweet_id                                                              \n","1440484799970304000             0.0             0.0             0.0   \n","1439618825171963904             0.0             3.0             0.0   \n","1248872872837332992             0.0             0.0             0.0   \n","1250729294051053568             0.0             3.0             0.0   \n","1249612131433095168             0.0             3.0             0.0   \n","\n","                     count_urls  likes  quotes  referenced_tweet_count  \\\n","tweet_id                                                                 \n","1440484799970304000         1.0     14       0                       0   \n","1439618825171963904         1.0      7       0                       0   \n","1248872872837332992         1.0     49       1                       0   \n","1250729294051053568         2.0      3       0                       0   \n","1249612131433095168         2.0     15       2                       0   \n","\n","                     replies  retweets  followers_count  following_count  \\\n","tweet_id                                                                   \n","1440484799970304000        8         0             2709             4999   \n","1439618825171963904        0         0              140              735   \n","1248872872837332992        0        20             7510             7260   \n","1250729294051053568        0         1             7510             7260   \n","1249612131433095168        0        21             7510             7260   \n","\n","                     tweet_count  listed_count  height  width   model_1  \n","tweet_id                                                                 \n","1440484799970304000           96            15     405    813  3.586778  \n","1439618825171963904           99             0    2048   1536  2.439114  \n","1248872872837332992          100           103     288    278  1.789965  \n","1250729294051053568          100           103    2048   2048  5.563298  \n","1249612131433095168          100           103    2048   2048  5.563298  "]},"metadata":{},"execution_count":36}],"metadata":{"id":"IylebrYzECmY","executionInfo":{"status":"ok","timestamp":1633638739329,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":42,"source":["# Question 5: Calculate and/or print the following five metrics for the \r\n","# model you ran in the prior steps: R-squared, R-squared adjusted, RMSE, \r\n","# MAE, and mean of the label column.\r\n","\r\n","print(results.rsquared)\r\n","print(results.rsquared_adj)\r\n","# print(results.rmse)\r\n","# print(results.mae)\r\n","# print(results.mean_y)"],"outputs":[{"output_type":"stream","name":"stdout","text":["0.10328031489225131\n","0.08266606925759046\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'OLSResults' object has no attribute 'mean'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18140/292767311.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# print(results.rmse)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# print(results.mae)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\statsmodels\\base\\wrapper.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_attrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mAttributeError\u001b[0m: 'OLSResults' object has no attribute 'mean'"]}],"metadata":{"id":"_6xVmDFzECt7","executionInfo":{"status":"ok","timestamp":1633638739330,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 6: We need to improve the model fit so that our predictions will\r\n","# be more accurate. Let's begin by incorporating the two date columns from\r\n","# the original dataset. Convert the features 'created_at_tweet' and \r\n","# 'created_at_author' to an integer representing the number of days since\r\n","# those dates until January 1st, 2022. Do not put these values into new \r\n","# columns. Replace the existing dates with those values. HINT: you will find\r\n","# many examples online of how to do this. But I used the strptime() method \r\n","# of the datetime package to cast \"2022-1-1\" into a date, subtract the column\r\n","# value from that date, and then return the result in days (.dt.days). Print\r\n","# the first five records of this new dataset.\r\n"],"outputs":[],"metadata":{"id":"0TTrsvDGGv7H","executionInfo":{"status":"ok","timestamp":1633638739330,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 7: Create another model that includes these two new columns\n","# representing the number of days since Jan 1, 2022. As before, eliminate\n","# all remaining non-numeric features and the other label candidates 'likes',\n","# 'quotes', and 'replies'. Print out the results summary.\n"],"outputs":[],"metadata":{"id":"8JMgz_Mvp9T1","executionInfo":{"status":"ok","timestamp":1633638739442,"user_tz":360,"elapsed":115,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 8: Once again, print out the fit metrics--R-squared, R-squared-adjusted,\n","# RMSE, MAE--as well as the label mean for this revised model. \n"],"outputs":[],"metadata":{"id":"0csUGODhSl5F","executionInfo":{"status":"ok","timestamp":1633638739443,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 9: We want to improve model fit even further by generating \n","# dummy codes for some of the categorical features that do not have too many \n","# group values like 'text' and 'url' do. In particular, generate dummy \n","# codes for 'lang', 'reply_settings', 'source', 'protected', 'verified', and\n","# 'terms' and include them in the original dataframe. Remove all remaining \n","# non-numeric features as well as the alternative labels 'likes', 'quotes', \n","# and 'replies'. Print out the first five records.\n"],"outputs":[],"metadata":{"id":"CFbKvKp2GRG2","executionInfo":{"status":"ok","timestamp":1633638739443,"user_tz":360,"elapsed":2,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 10: Generate another model using all remaining numeric features\n","# along with these new dummy codes AND the days since dates features we \n","# created previously. Print out the results summary.\n"],"outputs":[],"metadata":{"id":"LPQ83yIPWDx2","executionInfo":{"status":"ok","timestamp":1633638739557,"user_tz":360,"elapsed":116,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 11: Now we have a fairly large number of features. But not all of\n","# them are significantly helping the model. Many of them have non-significant\n","# p-values or may be suffering from excessive multi-collinearity. Calculate\n","# the VIF score for each feature and add it to a new DataFrame. Sort the \n","# DataFrame from largest to smallest VIF score and display it in the output.\n","# HINT: There may be a function in the book to help you with this.\n","\n"],"outputs":[],"metadata":{"id":"tHa6oRPFZe67","executionInfo":{"status":"ok","timestamp":1633638739558,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 12: We need to eliminate those features with excessive \n","# multi-collinearity. However, this may happen naturally as we remove\n","# those features with large p-values. Therefore, start by removing the \n","# feature with the highest p-value and then rerun the prior model. \n","# One-at-a-time, continue removing the feature with the highest p-value \n","# (rerunning the model each time) until the difference between R-squared\n","# and R-squared adjusted is <= 0.01. Why, because when R-squared adjusted\n","# is significantly lower than R-squared, we have too many variables in\n","# the model that are not significantly contributing to model fit. Once\n","# more, remove the highest p-value feature one-at-a-time until R-squared \n","# minus R-squared adjusted is <= 0.10. You do NOT need to keep the results\n","# summary of every model. You can overwrite the prior model summary each \n","# time until you meet the criterion.\n"],"outputs":[],"metadata":{"id":"FN00salHZl1G","executionInfo":{"status":"ok","timestamp":1633638739558,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 13: For the remaining features in the last model you produced\n","# where the difference between R2 and R2-adj is <= 0.01, calculate the VIF\n","# scores and print them out in a table from largest VIF to smallest.\n"],"outputs":[],"metadata":{"id":"-a_sOLPRdAho","executionInfo":{"status":"ok","timestamp":1633638739558,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 14: Now we have a nice and trim model. However, we cannot \n","# compare the coefficients to each other since they are each on different\n","# scales. Therefore, use a Min-Max normalization to convert all features\n","# and label to the same scale. Print out the first five records.\n"],"outputs":[],"metadata":{"id":"o8m3hZLiZ0Yv","executionInfo":{"status":"ok","timestamp":1633638739559,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 15: Rerun your last model using the normalized values. Print\n","# the results summary.\n"],"outputs":[],"metadata":{"id":"PEHSIQejc8jN","executionInfo":{"status":"ok","timestamp":1633638739674,"user_tz":360,"elapsed":118,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 16: Now that we have addressed multi-collinearity and have\n","# standardized the features, we should examine and address skewness. Print\n","# the skewness score for the label 'retweets'. In addition, use the .histplot()\n","# object from the seaborn package to print out a histogram of 'retweets'.\n"],"outputs":[],"metadata":{"id":"4jz1yihEeK4I","executionInfo":{"status":"ok","timestamp":1633638739675,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 17: The skewness of retweets is clearly very extreme. However, we cannot \n","# create a natural log transformation since there are zero values (ln(0) = undefined).\n","# Therefore, we need to +1 to all values before we calculate the natural log. \n","# Thankfully, there is a numpy method for that: np.log1p(). Convert the 'retweets' \n","# label to a natural log +1. Print out the new skewness and histogram.\n"],"outputs":[],"metadata":{"id":"7kS4UZ7HgJrZ","executionInfo":{"status":"ok","timestamp":1633638739675,"user_tz":360,"elapsed":3,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}},{"cell_type":"code","execution_count":null,"source":["# Question 18: Rerun the last MLR model using this new natural log +1 version\n","# of 'retweets'. Print out the results summary.\n"],"outputs":[],"metadata":{"id":"l18OC0kcfSV6","executionInfo":{"status":"ok","timestamp":1633638739675,"user_tz":360,"elapsed":2,"user":{"displayName":"Mark Keith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiISgHTD0uohYa-QGHVHJt9uoH8LFCBfx2XJmIl6A=s64","userId":"01471376858192886314"}}}}]}