{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Find Tweets that DON'T have images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import requests\r\n",
    "import pandas as pd\r\n",
    "import json\r\n",
    "import time\r\n",
    "\r\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAGnaTwEAAAAAhRdM6yLmei6skyaWcjbx8IDFnlw%3DLPQHO2CTw1nVjjHLx3htgP9qmeCOgPpt96EdDujokNcWljI5iP'\r\n",
    "headers = {'Authorization':('Bearer '+ bearer_token)}\r\n",
    "\r\n",
    "n = 10                            # The total number of tweets we want\r\n",
    "max_results = 10                  # The number of tweets to pull per request; must be between 10 and 100\r\n",
    "total_retrieved = 0               # To keep track of when to stop\r\n",
    "next_token = \"\"                   # Must be empty on first iteration\r\n",
    "search_term = \"manchester%20united\"             # To form an advanced query, see here: https://twitter.com/search-advanced?lang=en\r\n",
    "since_id = \"1371600000000000000\"  # The id of the oldest tweet you want to retrieve\r\n",
    "\r\n",
    "# Create empty DataFrames and set columns\r\n",
    "df_tweets = pd.DataFrame(columns=['tweet_id', 'author_id', 'retweet_count', 'like_count', 'text', 'language', 'created_at', 'source', 'possibly_sensitive', 'image_url'])\r\n",
    "df_users = pd.DataFrame(columns=['user_id', 'username', 'created_at', 'description', 'profile_image_url', 'protected', 'verified', 'followers_count', 'following_count', 'tweet_count', 'listed_count'])\r\n",
    "\r\n",
    "\r\n",
    "# stop when we have n results\r\n",
    "while total_retrieved < n:\r\n",
    "\r\n",
    "  # the first time through the loop, we do not need the next_token parameter\r\n",
    "  if next_token == \"\":\r\n",
    "    # url = f'https://api.twitter.com/2/tweets/search/recent?query={search_term}&max_results={max_results}&since_id={since_id}'\r\n",
    "    url = f'https://api.twitter.com/2/tweets/search/recent?query={search_term}&max_results={max_results}'\r\n",
    "  else:\r\n",
    "    # url = f'https://api.twitter.com/2/tweets/search/recent?query={search_term}&max_results={max_results}&since_id={since_id}&next_token={next_token}'\r\n",
    "    url = f'https://api.twitter.com/2/tweets/search/recent?query={search_term}&max_results={max_results}&next_token={next_token}'\r\n",
    "\r\n",
    "  url = 'https://api.twitter.com/2/tweets/search/recent?query=machester%20united&max_results=10&tweet.fields=attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,possibly_sensitive,public_metrics,referenced_tweets,reply_settings,source,text,withheld&expansions=geo.place_id,author_id,attachments.media_keys&media.fields=media_key,type,url&user.fields=created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld'\r\n",
    "\r\n",
    "  # make the request to the Twitter API Recent Search endpoint\r\n",
    "  response = requests.request(\"GET\", url, headers=headers)\r\n",
    "  try:  # Just in case we get an error\r\n",
    "    json_data = json.loads(response.text)\r\n",
    "    # print(json_data)\r\n",
    "  except:\r\n",
    "    print(response.text)\r\n",
    "\r\n",
    "  for tweet in json_data['data']:\r\n",
    "    media_key = \"\"  # Reset to empty each time through the loop so that we can use it for a condition later\r\n",
    "\r\n",
    "    # Store the data into variables\r\n",
    "    tweet_id = tweet['id']\r\n",
    "    author_id = tweet['author_id']                               \r\n",
    "    retweet_count = tweet['public_metrics']['retweet_count']     #label\r\n",
    "    like_count = tweet['public_metrics']['like_count']           #label\r\n",
    "    image_url = \"\"                                               #image\r\n",
    "    text = tweet['text']                                         #text\r\n",
    "    created_at = tweet['created_at']                             #categorical\r\n",
    "    source = tweet['source']                                     #categorical\r\n",
    "    possibly_sensitive = tweet['possibly_sensitive']             #categorical\r\n",
    "    language = tweet['lang']                                     #categorical\r\n",
    "\r\n",
    "    # Find out if there is media\r\n",
    "    if 'attachments' in tweet:\r\n",
    "      if 'media_keys' in tweet['attachments']:\r\n",
    "        media_key = tweet['attachments']['media_keys'][0]\r\n",
    "\r\n",
    "    # If there is a media key in this tweet, iterate through tweet['includes']['media'] until we find it\r\n",
    "    if media_key != \"\":\r\n",
    "      for media in json_data['includes']['media']:\r\n",
    "        if media['media_key'] == media_key: # Only if the media_key matches the one we stored\r\n",
    "          if media['type'] == 'photo':      # Only if it is a photo; ignore videos\r\n",
    "            image_url = media['url']        # Store the url in a variable\r\n",
    "\r\n",
    "    # Add the new data to a new record in the DataFrame\r\n",
    "    df_tweets.loc[tweet_id] = [tweet_id, author_id, retweet_count, like_count, text, language, created_at, source, possibly_sensitive, image_url]\r\n",
    "\r\n",
    "  # keep track of how many results have been obtained so far:\r\n",
    "  total_retrieved += 1\r\n",
    "  \r\n",
    "\r\n",
    "  # keep track of where to start next time, but quit if there are no more results\r\n",
    "  try:\r\n",
    "    next_token = json_data['meta']['next_token']\r\n",
    "  except:\r\n",
    "    break  \r\n",
    "\r\n",
    "  # get user info\r\n",
    "  for user in json_data['includes']['users']:\r\n",
    "    user_id = user['id']\r\n",
    "    user_name = user['username']\r\n",
    "    user_created_at = user['created_at']\r\n",
    "    user_description = user['description']\r\n",
    "    user_profile_image_url = user['profile_image_url']\r\n",
    "    user_protected = user['protected']\r\n",
    "    user_verified = user['verified']\r\n",
    "    user_followers_count = user['public_metrics']['followers_count']\r\n",
    "    user_following_count = user['public_metrics']['following_count']\r\n",
    "    user_tweet_count = user['public_metrics']['tweet_count']\r\n",
    "    user_listed_count = user['public_metrics']['listed_count']\r\n",
    "\r\n",
    "    #put user info into a user dataframe\r\n",
    "    df_users.loc[user_id] = [user_id, user_name, user_created_at, user_description, user_profile_image_url, user_protected, user_verified, user_followers_count, user_following_count, user_tweet_count, user_listed_count]\r\n",
    "  \r\n",
    "\r\n",
    "  #sleep to avoid hitting the rate limit\r\n",
    "  # print('sleeping')\r\n",
    "  # time.sleep(1)\r\n",
    "\r\n",
    "#set df indexes\r\n",
    "df_tweets.set_index('tweet_id', inplace=True)\r\n",
    "df_users.set_index('user_id', inplace=True)\r\n",
    "\r\n",
    "# df.to_csv('twitter.csv')\r\n",
    "df_users.head()  "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>description</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>protected</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>listed_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1155833642234589186</th>\n",
       "      <td>hakangokdemir_</td>\n",
       "      <td>2019-07-29T13:33:09.000Z</td>\n",
       "      <td>Futbol üzerine,</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/134648309...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>764</td>\n",
       "      <td>443</td>\n",
       "      <td>2162</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086254727686443008</th>\n",
       "      <td>Noticiasde_</td>\n",
       "      <td>2019-01-18T13:31:23.000Z</td>\n",
       "      <td>Noticias de último momento</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/108625508...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>297</td>\n",
       "      <td>259252</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139820970</th>\n",
       "      <td>LaProvinciaBsAs</td>\n",
       "      <td>2010-05-03T19:50:21.000Z</td>\n",
       "      <td>Multimedios: Portal de Noticias GLP | 18 Años ...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/133890848...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31859</td>\n",
       "      <td>959</td>\n",
       "      <td>447368</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284267418387349511</th>\n",
       "      <td>YallicoMarco</td>\n",
       "      <td>2020-07-17T23:23:52.000Z</td>\n",
       "      <td></td>\n",
       "      <td>https://pbs.twimg.com/profile_images/133925095...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>1015</td>\n",
       "      <td>386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375840723917025284</th>\n",
       "      <td>RodrigoBallena</td>\n",
       "      <td>2021-03-27T16:03:01.000Z</td>\n",
       "      <td>Tweets sobre el fútbol peruano y  internaciona...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/143899948...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>971</td>\n",
       "      <td>200</td>\n",
       "      <td>2637</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            username                created_at  \\\n",
       "user_id                                                          \n",
       "1155833642234589186   hakangokdemir_  2019-07-29T13:33:09.000Z   \n",
       "1086254727686443008      Noticiasde_  2019-01-18T13:31:23.000Z   \n",
       "139820970            LaProvinciaBsAs  2010-05-03T19:50:21.000Z   \n",
       "1284267418387349511     YallicoMarco  2020-07-17T23:23:52.000Z   \n",
       "1375840723917025284   RodrigoBallena  2021-03-27T16:03:01.000Z   \n",
       "\n",
       "                                                           description  \\\n",
       "user_id                                                                  \n",
       "1155833642234589186                                    Futbol üzerine,   \n",
       "1086254727686443008                         Noticias de último momento   \n",
       "139820970            Multimedios: Portal de Noticias GLP | 18 Años ...   \n",
       "1284267418387349511                                                      \n",
       "1375840723917025284  Tweets sobre el fútbol peruano y  internaciona...   \n",
       "\n",
       "                                                     profile_image_url  \\\n",
       "user_id                                                                  \n",
       "1155833642234589186  https://pbs.twimg.com/profile_images/134648309...   \n",
       "1086254727686443008  https://pbs.twimg.com/profile_images/108625508...   \n",
       "139820970            https://pbs.twimg.com/profile_images/133890848...   \n",
       "1284267418387349511  https://pbs.twimg.com/profile_images/133925095...   \n",
       "1375840723917025284  https://pbs.twimg.com/profile_images/143899948...   \n",
       "\n",
       "                    protected verified followers_count following_count  \\\n",
       "user_id                                                                  \n",
       "1155833642234589186     False    False             764             443   \n",
       "1086254727686443008     False    False             269             297   \n",
       "139820970               False    False           31859             959   \n",
       "1284267418387349511     False    False              19            1015   \n",
       "1375840723917025284     False    False             971             200   \n",
       "\n",
       "                    tweet_count listed_count  \n",
       "user_id                                       \n",
       "1155833642234589186        2162            9  \n",
       "1086254727686443008      259252            6  \n",
       "139820970                447368          184  \n",
       "1284267418387349511         386            0  \n",
       "1375840723917025284        2637            3  "
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find tweets that DO have images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# In this example, only those tweets with photos/images are stored\r\n",
    "\r\n",
    "n = 20                           # The total number of tweets we want\r\n",
    "max_results = 10                 # The number of tweets to pull per request; must be between 10 and 100\r\n",
    "total_retrieved = 0               # To keep track of when to stop\r\n",
    "next_token = \"\"                   # Must be empty on first iteration\r\n",
    "search_term = \"manchester%20united\"             # To form an advanced query, see here: https://twitter.com/search-advanced?lang=en\r\n",
    "since_id = \"1371590000000000000\"  # The id of the oldest tweet you want to retrieve\r\n",
    "\r\n",
    "# Create the empty DataFrame with the columns you want\r\n",
    "df_img = pd.DataFrame(columns=['id', 'retweets', 'likes', 'url', 'text'])\r\n",
    "df_img.set_index('id', inplace=True)\r\n",
    "\r\n",
    "# stop when we have n results\r\n",
    "while total_retrieved < n:\r\n",
    "\r\n",
    "  # the first time through the loop, we do not need the next_token parameter\r\n",
    "  if next_token == \"\":\r\n",
    "    # url = f'https://api.twitter.com/2/tweets/search/recent?query={search_term}&max_results={max_results}&since_id={since_id}'\r\n",
    "    url = f'https://api.twitter.com/2/tweets/search/recent?query={search_term}&max_results={max_results}'\r\n",
    "  else:\r\n",
    "    # url = f'https://api.twitter.com/2/tweets/search/recent?query={search_term}&max_results={max_results}&since_id={since_id}&next_token={next_token}'\r\n",
    "    url = f'https://api.twitter.com/2/tweets/search/recent?query={search_term}&max_results={max_results}&next_token={next_token}'\r\n",
    "\r\n",
    "  # These are the extra parameters we will add to the querystring; we won't store them all though; just want you to see what's possible\r\n",
    "  url += f'&tweet.fields=attachments,public_metrics,text'\r\n",
    "  url += f'&expansions=attachments.media_keys'\r\n",
    "  url += f'&media.fields=media_key,type,url'\r\n",
    "\r\n",
    "  # make the request to the Twitter API Recent Search endpoint\r\n",
    "  response = requests.request(\"GET\", url, headers=headers)\r\n",
    "  try:  # Just in case we get an error\r\n",
    "    json_data = json.loads(response.text)\r\n",
    "  except:\r\n",
    "    print(response.text)\r\n",
    "  \r\n",
    "\r\n",
    "  for tweet in json_data['data']:\r\n",
    "    media_key = \"\"  # Reset to empty each time through the loop so that we can use it for a condition later\r\n",
    "\r\n",
    "    # Store the data into variables\r\n",
    "    tweet_id = tweet['id']\r\n",
    "    retweet_count = tweet['public_metrics']['retweet_count']\r\n",
    "    like_count = tweet['public_metrics']['like_count']\r\n",
    "    image_url = \"\"\r\n",
    "    text = tweet['text']\r\n",
    "\r\n",
    "    # Find out if there is media\r\n",
    "    if 'attachments' in tweet:\r\n",
    "      if 'media_keys' in tweet['attachments']:\r\n",
    "        media_key = tweet['attachments']['media_keys'][0]\r\n",
    "\r\n",
    "    # If there is a media key in this tweet, iterate through tweet['includes']['media'] until we find it\r\n",
    "    if media_key != \"\":\r\n",
    "      for media in json_data['includes']['media']:\r\n",
    "        if media['media_key'] == media_key: # Only if the media_key matches the one we stored\r\n",
    "          if media['type'] == 'photo':      # Only if it is a photo; ignore videos\r\n",
    "            image_url = media['url']        # Store the url in a variable\r\n",
    "            \r\n",
    "            # Only iterate if a photo is found\r\n",
    "            total_retrieved += 1\r\n",
    "            \r\n",
    "            # Only add the record in the DataFrame if a photo is found\r\n",
    "            df_img.loc[tweet_id] = [retweet_count, like_count, image_url, text]\r\n",
    "            break\r\n",
    "\r\n",
    "  # keep track of where to start next time, but quit if there are no more results\r\n",
    "  try:\r\n",
    "    next_token = json_data['meta']['next_token']\r\n",
    "  except:\r\n",
    "    break  \r\n",
    "\r\n",
    "print(f'Number of records:\\t{len(df_img)}')\r\n",
    "# df_img.to_csv('twitter.csv')\r\n",
    "df_img.head()  "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "f8ec8e2802e9ec64c1de1126b52a3a3eba2bbbc7f0465a520b33d3486dfa46c4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}